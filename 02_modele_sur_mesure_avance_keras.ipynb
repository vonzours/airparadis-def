{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc00dbf5-53c1-4a18-9608-a043a37cccc3",
   "metadata": {},
   "source": [
    "# Modèle sur mesure avancé — TensorFlow / Keras\n",
    "\n",
    "Ce notebook entraîne un modèle deep learning à partir des données préparées :\n",
    "\n",
    "\n",
    "Les runs sont enregistrés dans la même expérience MLflow que le modèle baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838cb227-3d02-4aef-91fb-2e2372c5884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeremy\\miniconda3\\envs\\sentiment\\lib\\site-packages\\mlflow\\utils\\requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources  # noqa: TID251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jeremy\\miniconda3\\envs\\sentiment\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Tracking URI: file:///C:/Users/Jeremy/IA/sentiment_tri/mlruns\n",
      "Train exists : True\n",
      "Val exists   : True\n",
      "Test exists  : True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score, roc_auc_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "TRAIN_PATH = \"data/processed/train.csv\"\n",
    "VAL_PATH = \"data/processed/val.csv\"\n",
    "TEST_PATH = \"data/processed/test.csv\"\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"label\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# MLflow (même dossier et même expérience que le notebook précédent)\n",
    "tracking_path = Path(\"mlruns\").resolve()\n",
    "tracking_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_path.as_uri())\n",
    "mlflow.set_experiment(\"AirParadis_Sentiment\")\n",
    "\n",
    "print(\"Tracking URI:\", mlflow.get_tracking_uri())\n",
    "print(\"Train exists :\", Path(TRAIN_PATH).exists())\n",
    "print(\"Val exists   :\", Path(VAL_PATH).exists())\n",
    "print(\"Test exists  :\", Path(TEST_PATH).exists())\n",
    "\n",
    "tf.keras.utils.set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe791e-3f89-48ba-806b-5912797eca82",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0339969f-88ba-4819-a4b7-ed9efa01ef83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (960000, 2)\n",
      "Val  : (320000, 2)\n",
      "Test : (320000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df = pd.read_csv(VAL_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "X_train = train_df[TEXT_COL].astype(str).values\n",
    "y_train = train_df[LABEL_COL].astype(int).values\n",
    "\n",
    "X_val = val_df[TEXT_COL].astype(str).values\n",
    "y_val = val_df[LABEL_COL].astype(int).values\n",
    "\n",
    "X_test = test_df[TEXT_COL].astype(str).values\n",
    "y_test = test_df[LABEL_COL].astype(int).values\n",
    "\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Val  :\", val_df.shape)\n",
    "print(\"Test :\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0dbc70-718d-4867-a270-c2f4368a8125",
   "metadata": {},
   "source": [
    "## Fonctions métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "529dfc0d-e454-4586-8dc4-356ab62bbbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_proba):\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "    y_proba = np.asarray(y_proba).astype(float)\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_proba),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be9d16-eb1b-46a1-a817-3690f86c4072",
   "metadata": {},
   "source": [
    "## Tokenization et padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9fdacf1-5a01-430d-bb72-8ce2a0ac5e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_SIZE: 50000\n",
      "SEQ_LEN: 64\n",
      "BATCH_SIZE: 256\n",
      "EPOCHS: 3\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 50_000\n",
    "SEQ_LEN = 64\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 3\n",
    "\n",
    "print(\"VOCAB_SIZE:\", VOCAB_SIZE)\n",
    "print(\"SEQ_LEN:\", SEQ_LEN)\n",
    "print(\"BATCH_SIZE:\", BATCH_SIZE)\n",
    "print(\"EPOCHS:\", EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c11a144-2ced-475e-9a18-df05c85e3d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pad: (960000, 64)\n",
      "X_val_pad  : (320000, 64)\n",
      "X_test_pad : (320000, 64)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=VOCAB_SIZE,\n",
    "    oov_token=\"<OOV>\"\n",
    ")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "def texts_to_padded(texts):\n",
    "    seq = tokenizer.texts_to_sequences(texts)\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        seq, maxlen=SEQ_LEN, padding=\"post\", truncating=\"post\"\n",
    "    )\n",
    "\n",
    "X_train_pad = texts_to_padded(X_train)\n",
    "X_val_pad = texts_to_padded(X_val)\n",
    "X_test_pad = texts_to_padded(X_test)\n",
    "\n",
    "print(\"X_train_pad:\", X_train_pad.shape)\n",
    "print(\"X_val_pad  :\", X_val_pad.shape)\n",
    "print(\"X_test_pad :\", X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384de8e1-74cb-4112-a6de-3f023ff08665",
   "metadata": {},
   "source": [
    "## Datasets TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64d9b78-f69c-4a8a-a564-458aa02020e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 64), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train_pad, y_train))\n",
    "    .shuffle(50_000, seed=RANDOM_STATE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_val_pad, y_val))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_test_pad, y_test))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50348fb3-aae0-4084-9be5-5a0d97a3f8f7",
   "metadata": {},
   "source": [
    "## Modèle Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcae5250-f009-4508-a44e-4bd90e9dc7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jeremy\\miniconda3\\envs\\sentiment\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jeremy\\miniconda3\\envs\\sentiment\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 64, 128)           6400000   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 128)               98816     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6507137 (24.82 MB)\n",
      "Trainable params: 6507137 (24.82 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = 128\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(SEQ_LEN,)),\n",
    "    layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBED_DIM),\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=False)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83e5a8-7c50-4af1-ae9f-7471aef21530",
   "metadata": {},
   "source": [
    "## Entraînement et évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aaf8391-ea2c-47f0-b7ca-8765d03120e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/22 10:59:06 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\Jeremy\\miniconda3\\envs\\sentiment\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jeremy\\miniconda3\\envs\\sentiment\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3750/3750 [==============================] - 599s 159ms/step - loss: 0.4233 - accuracy: 0.8052 - val_loss: 0.3907 - val_accuracy: 0.8234\n",
      "Epoch 2/3\n",
      "3750/3750 [==============================] - 584s 156ms/step - loss: 0.3667 - accuracy: 0.8368 - val_loss: 0.3890 - val_accuracy: 0.8255\n",
      "Epoch 3/3\n",
      "3750/3750 [==============================] - 632s 169ms/step - loss: 0.3271 - accuracy: 0.8572 - val_loss: 0.4236 - val_accuracy: 0.8216\n",
      "1250/1250 [==============================] - 48s 38ms/step\n",
      "1250/1250 [==============================] - 48s 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/22 11:30:59 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jeremy\\AppData\\Local\\Temp\\tmpvtsuofky\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jeremy\\AppData\\Local\\Temp\\tmpvtsuofky\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'accuracy': 0.82160625, 'f1': 0.822288218959742, 'precision': 0.8191567221574416, 'recall': 0.82544375, 'roc_auc': 0.8993071121875}\n",
      "Test metrics: {'accuracy': 0.8199625, 'f1': 0.8203677951621654, 'precision': 0.8185251552369931, 'recall': 0.82221875, 'roc_auc': 0.8984801896484375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeremy\\miniconda3\\envs\\sentiment\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"sur_mesure_avance_keras\"):\n",
    "\n",
    "    mlflow.log_param(\"model_type\", \"sur_mesure_avance_keras\")\n",
    "    mlflow.log_param(\"vocab_size\", VOCAB_SIZE)\n",
    "    mlflow.log_param(\"seq_len\", SEQ_LEN)\n",
    "    mlflow.log_param(\"embed_dim\", EMBED_DIM)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "\n",
    "    t0 = time.time()\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1\n",
    "    )\n",
    "    mlflow.log_metric(\"train_time_sec\", time.time() - t0)\n",
    "\n",
    "    val_proba = model.predict(X_val_pad, batch_size=BATCH_SIZE).ravel()\n",
    "    test_proba = model.predict(X_test_pad, batch_size=BATCH_SIZE).ravel()\n",
    "\n",
    "    val_metrics = compute_metrics(y_val, val_proba)\n",
    "    test_metrics = compute_metrics(y_test, test_proba)\n",
    "\n",
    "    for k, v in val_metrics.items():\n",
    "        mlflow.log_metric(\"val_\" + k, float(v))\n",
    "    for k, v in test_metrics.items():\n",
    "        mlflow.log_metric(\"test_\" + k, float(v))\n",
    "\n",
    "    mlflow.tensorflow.log_model(model, \"model\")\n",
    "\n",
    "print(\"Validation metrics:\", val_metrics)\n",
    "print(\"Test metrics:\", test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e4147-20a9-4a37-ae7b-4fa96c322742",
   "metadata": {},
   "source": [
    "## Analyse rapide (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b10855e-54e1-4811-80ec-39df08f4b9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82    160000\n",
      "           1       0.82      0.83      0.82    160000\n",
      "\n",
      "    accuracy                           0.82    320000\n",
      "   macro avg       0.82      0.82      0.82    320000\n",
      "weighted avg       0.82      0.82      0.82    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_pred = (val_proba >= 0.5).astype(int)\n",
    "print(classification_report(y_val, val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fa026-8422-4698-bc19-c4ede1b9b0c6",
   "metadata": {},
   "source": [
    "## Export du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc92f488-7ec1-4863-9d00-6bd99bf243ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exported_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exported_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "- exported_model\n",
      "- artifacts/sur_mesure_avance_keras_metrics.json\n"
     ]
    }
   ],
   "source": [
    "export_dir = \"exported_model\"\n",
    "if os.path.exists(export_dir):\n",
    "    import shutil\n",
    "    shutil.rmtree(export_dir)\n",
    "\n",
    "model.save(export_dir)\n",
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "with open(\"artifacts/sur_mesure_avance_keras_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"val\": val_metrics, \"test\": test_metrics}, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"-\", export_dir)\n",
    "print(\"- artifacts/sur_mesure_avance_keras_metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6858d0a-7621-45d3-b209-863a215bfe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - fichiers créés :\n",
      "- artifacts/tokenizer.json\n",
      "- artifacts/preprocess_config.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "\n",
    "with open(\"artifacts/tokenizer.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(tokenizer.to_json())\n",
    "\n",
    "with open(\"artifacts/preprocess_config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"seq_len\": SEQ_LEN}, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"OK - fichiers créés :\")\n",
    "print(\"- artifacts/tokenizer.json\")\n",
    "print(\"- artifacts/preprocess_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280cbc74-1781-4a8f-8164-d1ef02839560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
